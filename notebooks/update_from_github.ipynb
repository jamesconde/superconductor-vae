{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Superconductor VAE from GitHub\n",
    "\n",
    "Run this notebook to pull the latest code from GitHub into your Google Drive repo.\n",
    "Preserves checkpoints and training logs. Invalidates tensor cache if data changed.\n",
    "\n",
    "**Keep this notebook on Drive** — reuse it anytime you need to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Update this path if your repo is in a different Drive location\n",
    "REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/SuperconductorVAE/superconductor-vae\"\n",
    "GITHUB_URL = \"https://github.com/jamesconde/superconductor-vae.git\"\n",
    "BRANCH = \"main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path(REPO_PATH)\n",
    "is_git_repo = (repo / '.git').exists()\n",
    "\n",
    "if is_git_repo:\n",
    "    # --- Fast path: git pull ---\n",
    "    print(\"Git repo detected — pulling latest changes...\")\n",
    "    !cd \"{REPO_PATH}\" && git fetch origin {BRANCH} && git reset --hard origin/{BRANCH}\n",
    "    print(\"Done!\")\n",
    "\n",
    "else:\n",
    "    # --- First time or tarball extraction: clone fresh, preserve outputs ---\n",
    "    print(\"No .git directory — cloning fresh from GitHub...\")\n",
    "    print(\"Preserving outputs/ (checkpoints, logs, norm_stats)...\")\n",
    "\n",
    "    # Save outputs we want to keep\n",
    "    preserve_dir = Path(\"/content/_preserved_outputs\")\n",
    "    preserve_dir.mkdir(exist_ok=True)\n",
    "    outputs_dir = repo / \"outputs\"\n",
    "\n",
    "    preserved_files = []\n",
    "    if outputs_dir.exists():\n",
    "        for f in outputs_dir.iterdir():\n",
    "            if f.is_file() and f.suffix in ('.pt', '.json', '.csv', '.log'):\n",
    "                dest = preserve_dir / f.name\n",
    "                print(f\"  Preserving: {f.name} ({f.stat().st_size / 1e6:.1f} MB)\")\n",
    "                shutil.copy2(str(f), str(dest))\n",
    "                preserved_files.append(f.name)\n",
    "\n",
    "    # Also preserve tensor cache if it exists\n",
    "    cache_dir = repo / \"data\" / \"processed\" / \"cache\"\n",
    "    preserved_cache = False\n",
    "    if cache_dir.exists():\n",
    "        print(f\"  Preserving tensor cache...\")\n",
    "        shutil.copytree(str(cache_dir), \"/content/_preserved_cache\", dirs_exist_ok=True)\n",
    "        preserved_cache = True\n",
    "\n",
    "    # Remove old repo and clone\n",
    "    if repo.exists():\n",
    "        shutil.rmtree(str(repo))\n",
    "    !git clone --branch {BRANCH} {GITHUB_URL} \"{REPO_PATH}\"\n",
    "\n",
    "    # Restore outputs\n",
    "    (repo / \"outputs\").mkdir(exist_ok=True)\n",
    "    for fname in preserved_files:\n",
    "        src = preserve_dir / fname\n",
    "        dest = repo / \"outputs\" / fname\n",
    "        shutil.copy2(str(src), str(dest))\n",
    "        print(f\"  Restored: {fname}\")\n",
    "\n",
    "    # Restore cache\n",
    "    if preserved_cache:\n",
    "        cache_dest = repo / \"data\" / \"processed\" / \"cache\"\n",
    "        cache_dest.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copytree(\"/content/_preserved_cache\", str(cache_dest), dirs_exist_ok=True)\n",
    "        print(\"  Restored tensor cache\")\n",
    "\n",
    "    # Cleanup temp\n",
    "    shutil.rmtree(str(preserve_dir), ignore_errors=True)\n",
    "    shutil.rmtree(\"/content/_preserved_cache\", ignore_errors=True)\n",
    "\n",
    "    print(f\"\\nDone! Repo is now a git clone at: {REPO_PATH}\")\n",
    "    print(\"Future updates will use fast 'git pull'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optional: Invalidate tensor cache ===\n",
    "# Run this cell if the dataset CSV or preprocessing config changed.\n",
    "# Training will rebuild the cache on next run (~2 min).\n",
    "\n",
    "cache_meta = Path(REPO_PATH) / \"data/processed/cache/cache_meta.json\"\n",
    "if cache_meta.exists():\n",
    "    cache_meta.unlink()\n",
    "    print(\"Tensor cache invalidated — will rebuild on next training run.\")\n",
    "else:\n",
    "    print(\"No cache to invalidate (already fresh or doesn't exist).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Verify ===\n",
    "print(\"Repo contents:\")\n",
    "!ls \"{REPO_PATH}/\"\n",
    "print()\n",
    "print(\"Latest commit:\")\n",
    "!cd \"{REPO_PATH}\" && git log --oneline -3\n",
    "print()\n",
    "print(\"Outputs:\")\n",
    "!ls -lh \"{REPO_PATH}/outputs/\" 2>/dev/null | head -10\n",
    "print()\n",
    "print(\"Now close this notebook and open train_colab.ipynb to start training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
